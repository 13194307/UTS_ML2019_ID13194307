{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/13194307/UTS_ML2019_ID13194307/blob/master/ML_A2/NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzMSrFr7rdcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "from scipy.special import softmax\n",
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAtP_X--sHAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        "    class Layer:\n",
        "        class Neuron:\n",
        "            def __init__(self, inputShape):\n",
        "                self.weights, self.bias = self.initialiseWeights(inputShape)\n",
        "                \n",
        "            def initialiseWeights(self, inputShape):\n",
        "                weights = np.array([np.random.randn() for _ in range(0, inputShape)]) / math.sqrt(inputShape)\n",
        "                bias = np.random.randn()\n",
        "                \n",
        "                return weights, bias\n",
        "            \n",
        "            def getWeightsAndBias(self):\n",
        "                return self.weights, self.bias\n",
        "            \n",
        "            def generateNeuronOutput(self, x):\n",
        "                return np.dot(self.weights, x) + self.bias\n",
        "            \n",
        "            \n",
        "            \n",
        "        \n",
        "        def __init__(self, layerType, neuronsPerLayer, inputShape):\n",
        "            self.layerType = layerType\n",
        "            self.numNeurons = neuronsPerLayer\n",
        "            self.inputShape = inputShape\n",
        "            self.neurons = [self.Neuron(inputShape) for _ in range(0, neuronsPerLayer)]\n",
        "            \n",
        "        def getInputShape(self):\n",
        "            return self.inputShape\n",
        "        \n",
        "        def getNumNeurons(self):\n",
        "            return self.numNeurons\n",
        "        \n",
        "        def generateLayerOutput(self, x):\n",
        "            layerOutput = []\n",
        "            \n",
        "            for neuron in self.neurons:\n",
        "                neuronOutput = neuron.generateNeuronOutput(x)\n",
        "                layerOutput.append(neuronOutput)\n",
        "               \n",
        "            #print(self.layerType, \":\", layerOutput)\n",
        "            if self.layerType == \"Dense\":\n",
        "                #ReLU activation\n",
        "                layerOutput = np.maximum(layerOutput, 0)\n",
        "            elif self.layerType == \"Output\":\n",
        "                if len(layerOutput) == 1:\n",
        "                    #Sigmoid activation\n",
        "                    layerOutput = 1 / (1 + math.exp(-1*layerOutput[0]))\n",
        "                else:\n",
        "                    #Softmax activation\n",
        "                    layerOutput = np.exp(layerOutput)/sum(np.exp(layerOutput))\n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "                    \n",
        "            return layerOutput\n",
        "            \n",
        "        def __str__(self):\n",
        "            output = \"\"\n",
        "            for neuron in self.neurons:\n",
        "                weights, bias = neuron.getWeightsAndBias()\n",
        "                output+=\"\\t\"\n",
        "                \n",
        "                for j in range(0, len(weights)):\n",
        "                    output+=(\"w{}: {}, \".format(j, weights[j]))\n",
        "                    \n",
        "                output+=(\"b0: {}\\n\".format(bias))\n",
        "            \n",
        "            return output\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    \n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        self.numLayers = 0\n",
        "        \n",
        "    def addLayer(self, layerType, neuronsPerLayer, inputShape=None):\n",
        "        if inputShape == None:\n",
        "            inputShape = self.layers[-1].getNumNeurons()\n",
        "            \n",
        "        self.layers.append(self.Layer(layerType, neuronsPerLayer, inputShape))\n",
        "        self.numLayers+=1\n",
        "        \n",
        "    def predict(self, x, labels):\n",
        "        probabilities = []\n",
        "        \n",
        "        for sampleX in x:\n",
        "            prob = self.feedForward(sampleX)\n",
        "            #print(pred)\n",
        "            probabilities.append(prob)\n",
        "      \n",
        "        predictions = np.argmax(probabilities, axis=1)\n",
        "        loss = self.calcLoss(probabilities, predictions, labels)\n",
        "        print(loss)\n",
        "        return predictions\n",
        "    \n",
        "    def feedForward(self, x):\n",
        "        lastLayerOutput = x\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            lastLayerOutput = layer.generateLayerOutput(lastLayerOutput)\n",
        "            \n",
        "        return lastLayerOutput\n",
        "    \n",
        "    def calcLoss(self, prob, pred, actual):\n",
        "        #print(np.log([prob[i][actual[i]] for i in range(0, len(actual))]))\n",
        "        loss = -1*sum(np.log([prob[i][actual[i]] for i in range(0, len(actual))]))\n",
        "        return loss\n",
        "        \n",
        "    def __str__(self):\n",
        "        output = \"\"\n",
        "        \n",
        "        for i in range(0, self.numLayers):\n",
        "            output+=(\"Layer {}:\\n\".format(i+1))\n",
        "            output+=str(self.layers[i])\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMEeIQ7_whBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = NeuralNetwork()\n",
        "nn.addLayer(\"Dense\", 20, inputShape=4)\n",
        "nn.addLayer(\"Dense\", 20)\n",
        "nn.addLayer(\"Dense\", 10)\n",
        "nn.addLayer(\"Output\", 3)\n",
        "#print(nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIUioca4zaw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_X, iris_y = load_iris(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBeLqlxqEhRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "iris_X_trimmed = iris_X\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "iris_X_scaled = scaler.fit_transform(iris_X_trimmed)\n",
        "iris_X_zscore = stats.zscore(iris_X_trimmed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjMHZ5k0GRM9",
        "colab_type": "code",
        "outputId": "cfd2893d-a510-4e2c-beb2-64f50c9febef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "pred = nn.predict(iris_X_zscore, iris_y)\n",
        "accuracy_score(pred, iris_y)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-2.77152267 -2.65329343 -2.84443032 -2.76971499 -2.8038399  -2.54258437\n",
            " -2.91226092 -2.84878741 -2.66364486 -2.79693923 -2.6113142  -2.94354231\n",
            " -2.69917471 -2.83629605 -2.4505205  -2.41749829 -2.52438895 -2.73088899\n",
            " -2.49997512 -2.65105134 -2.73327674 -2.66650888 -2.83024239 -2.75023836\n",
            " -3.0167926  -2.6676129  -2.7817369  -2.74789921 -2.74857567 -2.86818063\n",
            " -2.76973781 -2.60761118 -2.5583149  -2.46610846 -2.75527276 -2.76535435\n",
            " -2.55271394 -2.889718   -2.72411104 -2.81306989 -2.74723513 -2.56639425\n",
            " -2.89180421 -2.65078346 -2.72465433 -2.61683318 -2.71884099 -2.8644132\n",
            " -2.66073541 -2.84274402 -0.18981897 -0.16725067 -0.16013614 -0.12322669\n",
            " -0.12845753 -0.1279022  -0.15720041 -0.13718861 -0.14275477 -0.15379191\n",
            " -0.10835147 -0.14750906 -0.11328437 -0.1194589  -0.16301983 -0.17892798\n",
            " -0.13813931 -0.13272604 -0.11094802 -0.13703133 -0.13768022 -0.14133673\n",
            " -0.11029977 -0.11249504 -0.14673934 -0.16114819 -0.13182344 -0.13533194\n",
            " -0.13453851 -0.15150061 -0.13162128 -0.13236742 -0.14520356 -0.11437425\n",
            " -0.14013546 -0.14702083 -0.16154199 -0.11194544 -0.14779384 -0.13797199\n",
            " -0.13034494 -0.12552648 -0.13896206 -0.13166409 -0.14107081 -0.13825566\n",
            " -0.14066942 -0.13474821 -0.15751597 -0.14536404 -3.24014572 -3.2489441\n",
            " -3.25170267 -3.38379413 -3.34181108 -3.37775358 -3.23206194 -3.38642805\n",
            " -3.66766204 -2.84665349 -2.92867129 -3.31845204 -3.18277185 -3.33198503\n",
            " -3.24991438 -3.02312508 -3.27080877 -2.7603061  -3.98792899 -3.46180275\n",
            " -3.09175794 -3.17197996 -3.60307514 -3.21939856 -3.03949175 -3.0526506\n",
            " -3.13575819 -3.06194388 -3.33870256 -3.12517611 -3.40976901 -2.67507154\n",
            " -3.34547602 -3.27567955 -3.54425975 -3.22543418 -2.97774037 -3.21175589\n",
            " -3.02766265 -3.04646439 -3.17784242 -2.97401102 -3.2489441  -3.18300533\n",
            " -3.06693419 -3.10797832 -3.36375561 -3.12036342 -2.91926731 -3.14261915]\n",
            "303.2999910587414\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N59zxfHfOMhw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "48fb8b45-14bf-4520-c5b4-2f996dcec6d6"
      },
      "source": [
        "print(pred)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 0 0 0 2 2 0 0 0 0 2 0 0 0 2 2 2 0 2 2 0 2 2 0 0 0 0 2 0 0 0 0 2 2 0 0 2\n",
            " 2 0 0 0 1 0 0 2 0 2 0 2 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 2 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 2 2 2 2 2 2 2 2 2 2 1\n",
            " 2 2 2 2 2 1 0 2 2 2 2 2 2 2 1 1 1 2 1 2 1 2 1 1 2 2 1 1 2 2 2 2 2 2 2 2 2\n",
            " 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmdudiMajbUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}