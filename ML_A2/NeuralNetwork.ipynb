{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/13194307/UTS_ML2019_ID13194307/blob/master/ML_A2/NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzMSrFr7rdcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "from scipy.special import softmax\n",
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAtP_X--sHAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        "    class Layer:\n",
        "        class Neuron:\n",
        "            def __init__(self, inputShape):\n",
        "                self.weights, self.bias = self.initialiseWeights(inputShape)\n",
        "                \n",
        "            def initialiseWeights(self, inputShape):\n",
        "                weights = np.array([np.random.randn() for _ in range(0, inputShape)]) / math.sqrt(inputShape)\n",
        "                bias = np.random.randn()\n",
        "                \n",
        "                return weights, bias\n",
        "            \n",
        "            def getWeightsAndBias(self):\n",
        "                return self.weights, self.bias\n",
        "            \n",
        "            def generateNeuronOutput(self, x):\n",
        "                return np.dot(self.weights, x) + self.bias\n",
        "            \n",
        "            \n",
        "            \n",
        "        \n",
        "        def __init__(self, layerType, neuronsPerLayer, inputShape):\n",
        "            self.layerType = layerType\n",
        "            self.numNeurons = neuronsPerLayer\n",
        "            self.inputShape = inputShape\n",
        "            self.neurons = [self.Neuron(inputShape) for _ in range(0, neuronsPerLayer)]\n",
        "            \n",
        "        def getInputShape(self):\n",
        "            return self.inputShape\n",
        "        \n",
        "        def getNumNeurons(self):\n",
        "            return self.numNeurons\n",
        "        \n",
        "        def generateLayerOutput(self, x):\n",
        "            layerOutput = []\n",
        "            \n",
        "            for neuron in self.neurons:\n",
        "                neuronOutput = neuron.generateNeuronOutput(x)\n",
        "                layerOutput.append(neuronOutput)\n",
        "               \n",
        "            #print(layerOutput)\n",
        "            if self.layerType == \"Dense\":\n",
        "                #ReLU activation\n",
        "                layerOutput = np.maximum(layerOutput, 0)\n",
        "            elif self.layerType == \"Output\":\n",
        "                layerOutput = 1 / (1 + math.exp(-1*layerOutput[0]))\n",
        "                #Softmax activation\n",
        "                #print(layerOutput)\n",
        "                #layerOutput = np.exp(layerOutput)/sum(np.exp(layerOutput))\n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "                    \n",
        "            return layerOutput\n",
        "            \n",
        "        def __str__(self):\n",
        "            output = \"\"\n",
        "            for neuron in self.neurons:\n",
        "                weights, bias = neuron.getWeightsAndBias()\n",
        "                output+=\"\\t\"\n",
        "                \n",
        "                for j in range(0, len(weights)):\n",
        "                    output+=(\"w{}: {}, \".format(j, weights[j]))\n",
        "                    \n",
        "                output+=(\"b0: {}\\n\".format(bias))\n",
        "            \n",
        "            return output\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "    \n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        self.numLayers = 0\n",
        "        \n",
        "    def addLayer(self, layerType, neuronsPerLayer, inputShape=None):\n",
        "        if inputShape == None:\n",
        "            inputShape = self.layers[-1].getNumNeurons()\n",
        "            \n",
        "        self.layers.append(self.Layer(layerType, neuronsPerLayer, inputShape))\n",
        "        self.numLayers+=1\n",
        "        \n",
        "    def predict(self, x):\n",
        "        prediction = []\n",
        "        \n",
        "        for sampleX in x:\n",
        "            pred = self.feedForward(sampleX)\n",
        "            #print(pred)\n",
        "            prediction.append(pred)\n",
        "      \n",
        "        prediction = np.array(prediction)\n",
        "        #print(prediction)\n",
        "        #prediction = softmax(prediction)\n",
        "        #print(prediction)\n",
        "        prediction[prediction > 0.5] = 1\n",
        "        prediction[prediction <= 0.5] = 0\n",
        "        return prediction\n",
        "    \n",
        "    def feedForward(self, x):\n",
        "        lastLayerOutput = x\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            lastLayerOutput = layer.generateLayerOutput(lastLayerOutput)\n",
        "            \n",
        "        return lastLayerOutput\n",
        "    \n",
        "    def softmax(self, x): \n",
        "        \"\"\"Compute softmax values for each sets of scores in x.\"\"\" \n",
        "\n",
        "        e_x = np.exp(x - np.max(x)) \n",
        "\n",
        "        return e_x / e_x.sum(axis=0) \n",
        "\n",
        "        # only difference\n",
        "        \n",
        "    def __str__(self):\n",
        "        output = \"\"\n",
        "        \n",
        "        for i in range(0, self.numLayers):\n",
        "            output+=(\"Layer {}:\\n\".format(i+1))\n",
        "            output+=str(self.layers[i])\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMEeIQ7_whBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "8d84e478-52af-4a9b-b0af-dfca0aa18184"
      },
      "source": [
        "nn = NeuralNetwork()\n",
        "nn.addLayer(\"Dense\", 3, inputShape=4)\n",
        "nn.addLayer(\"Dense\", 3)\n",
        "nn.addLayer(\"Dense\", 3)\n",
        "nn.addLayer(\"Output\", 1)\n",
        "print(nn)"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 1:\n",
            "\tw0: 0.23795143630272864, w1: -0.40157947893520496, w2: 0.9667570445752864, w3: 0.3464894017838772, b0: -0.990269908081075\n",
            "\tw0: 1.2057983733547877, w1: 0.0032066647947672335, w2: -0.1630241899405391, w3: -0.4895011618074342, b0: 1.310639937361324\n",
            "\tw0: 0.4976200108852722, w1: -0.16288868351125418, w2: 0.10906928530296535, w3: 0.5306781839393346, b0: 0.3697303918278565\n",
            "Layer 2:\n",
            "\tw0: 0.12196677001087997, w1: -0.6930418425458341, w2: 0.06470342257724876, b0: -0.6216387976850688\n",
            "\tw0: 0.2210988659682155, w1: 0.036382628764374494, w2: -0.2803129512051275, b0: 1.806560703542133\n",
            "\tw0: 0.13880406514241345, w1: 0.5790437695253757, w2: 0.5253856387461914, b0: -1.5082299209762575\n",
            "Layer 3:\n",
            "\tw0: -0.6260244842037828, w1: 0.1311912025512874, w2: -0.8501278219041793, b0: 0.3400664388249166\n",
            "\tw0: -1.5161681778415141, w1: 0.4334792183225777, w2: 0.07633195498906958, b0: -0.6587810878645449\n",
            "\tw0: -0.13823219585409957, w1: 0.01814875783861039, w2: 0.47906492161955966, b0: 0.5609435641359658\n",
            "Layer 4:\n",
            "\tw0: 1.2653023188570562, w1: -0.25561255237649666, w2: 0.5770203845542901, b0: 1.0479774062261462\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIUioca4zaw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_X, iris_y = load_iris(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBeLqlxqEhRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "iris_X_trimmed = iris_X\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "iris_X_scaled = scaler.fit_transform(iris_X_trimmed)\n",
        "iris_X_zscore = stats.zscore(iris_X_trimmed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjMHZ5k0GRM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e5b7665-bc63-43c9-a595-02c23c0271f0"
      },
      "source": [
        "pred = nn.predict(iris_X_zscore)\n",
        "accuracy_score(pred, iris_y)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N59zxfHfOMhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}