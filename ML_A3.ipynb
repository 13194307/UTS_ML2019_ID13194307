{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML A3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/13194307/UTS_ML2019_ID13194307/blob/master/ML_A3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snqKD0_4-GYn",
        "colab_type": "text"
      },
      "source": [
        "# Link to Github Repo\n",
        "\n",
        "https://github.com/13194307/UTS_ML2019_ID13194307"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ6JcIYRxeCK",
        "colab_type": "text"
      },
      "source": [
        "# Question 4:\n",
        "**One of the themes in the machine learning models we've looked at this semester is\n",
        "large numbers of parameters that are changed by tiny amounts. Why do so many\n",
        "apparently different models use such similar techniques? Are there other ways to\n",
        "approach the problem of learning? Are there also commonalities in the way the\n",
        "amounts to be changed are determined? (800-1000 words)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8H9YmB1xple",
        "colab_type": "text"
      },
      "source": [
        "# Answer\n",
        "\n",
        "This answer will be split into 3 sections, with each section addressing a different part of the question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puNObDNCxmc0",
        "colab_type": "text"
      },
      "source": [
        "**Why do so many apparently different models use such similar techniques?**\n",
        "\n",
        "The reason as to why so many models learn by making small changes to a large number of parameters is due to the nature of machine learning problems themselves. Most models operate under a fundamental assumption that for any machine learning problem, there exists some function that governs the distribution of the data points. This assumption is neither baseless nor naive and mathematical functions form the backbone of many things in the world, a point thoroughly discussed in an essay by Ransford [1]. Therefore the goal of machine learning can be reframed as trying to find a function that best approximates the actual function for the distribution of the data, with each trainable parameter representing a variable of the function. The vast majority of machine learning problems are non-trivial and in order to generate a function that captures the intricacies of a complex problem, a large number of parameters are needed. This is why most models utilise a large number of parameters. \n",
        "\n",
        "Realistically, no model will be able to create a function that completely replicates the actual distribution of the dataset as such a task would not only require a currently-unachievable amount of processing power and memory but also an extremely large (perhaps infinite) sample size. As a result, models treat the task of finding the ideal function as an optimisation problem where some loss or cost function is minimised. One question remains however; given a dataset following the rules of some unknown function, how do you find the optimal parameter configuration that provides minimal loss? One way would be to greedily try every possible parameter configuration, but this would be computationally intractable. The domain of this greedy search could be constrained. However there would need to be some way of determining the appropriate constraints and even with constraints, this operation would also most likely be intractable. A more reasonable alternative would be to, given some starting configuration, change the value of the weights in some direction that will reduce the loss. Small steps, rather than large steps, should be taken as although moving in some direction might reduce loss in the short term, the complex nature of most data distributions makes it unlikely that constantly moving in this same direction will consistently yield parameter configurations that produce less loss.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-lBQbBOEfOb",
        "colab_type": "text"
      },
      "source": [
        "**Are there other ways to approach the problem of learning?**\n",
        "\n",
        "The typical approach of making small changes to a large number of parameters works well for many models. However there are other ways of approaching the problem of machine learning. Some of these approaches are only theoretical while others are currently used in practise for machine learning problems.\n",
        "\n",
        "One approach, which was mentioned previously, is a greedy search for the parameter configuration that produces the least amount of loss. This is a purely theoretical method of machine learning and has many problems associated with it, were it to be implemented. Firstly, without some constraints on the search domain, this search would be impossible to perform. As the constraints get stricter, the search time decreases but the chance of finding the optimal parameter configuration decreases as well. Determining the constraints would also be problematic as there isn't much that could be used to discover the ideal domain constrains. A big advantage of this method is that, unlike the typical gradient descent approaches, a greedy approach would not get stuck in local minimas. However this advantage, for now, is not enough to offset the vast amount of computational power required.\n",
        "\n",
        "Many models choose to either have only untrainable parameters or no parameters at all. The K-Nearest Neighbours (KNN) algorithm [6] is an example of such a model. Its only parameter is the variable K, which determines the number of neighbours to be considered when making predictions. Instead of updating weights or parameters during training, the KNN algorithm simply stores the value of the training data points. The class of an input data point is decided through a vote from the K nearest data points processed during training. It is possible to optimise the value of K and therefore indirectly turn K into a trainable parameter. However, as of now, there is no way to directly link the value of K to the loss function and therefore no way to determine the direction to shift the value of K. Instead, the optimisation process would require a greedy approach where various values of K and the losses they produce are compared. A Naive Bayes Classifier [7] has no parameters at all, and predictions are made through applying Bayes Theorem under the assumption that the input attributes are independent of each other. Due to the fact that there are no parameters, no optimisation can be conducted on a Naive Bayes Classifier. While the simplicity of both of these models could be considered an advantage in some situations, it often hinders their performance especially when compared to other models which can more easily capture the complex nature of machine learning problems.\n",
        "\n",
        "Other models have parameters that define a function, but the value of these parameters are determined through other means. A Support Vector Machine (SVM) is a model which attempts to find the best hyperplane that linearly separates the data. While a soft-margin SVM has a cost function that needs to be minimised, a hard-margin SVM assumes that the dataset is linearly separable when the data is either kept in its original dimensions or is converted to a higher dimensional representation. Therefore, no cost function is needed since it operates under the belief that it can find a function with no loss on the training data. With this assumption, the best fit hyperplane is defined as the one that maximises the margins between the support vectors. The ideal parameters for the separating hyperplane is determined through application of linear algebra techniques, such as analysis of the saddle points of Lagrangians [2]. This approach sidesteps the need to constantly make small changes to parameter and despite their lack of trainable parameters, SVMs are well known for achieving high levels of performance on many classification problems. However for hard-margin SVMs, the pre-condition of the data being linearly separable, when in reality this is often not true, limits the usefulness of this approach.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjUoqY-JEiHF",
        "colab_type": "text"
      },
      "source": [
        "**Are there also commonalities in the way the amounts to be changed are determined?**\n",
        "\n",
        "Most models utilise gradient descent to dictate how parameters are changed. Gradient descent involves calculating the derivative for each parameter with respect to some loss or cost function. This will give the gradient, with the polarity of the gradient representing the direction where loss will increase. Therefore to generate a decrease in loss, the values of the parameters should be shifted in the direction opposite to that of the gradient. The magnitude of the change in parameters is simply the gradient multiplied by some predetermined step size. Neural networks are well known for making use of gradient descent, with it forming the backbone of the famous backpropagation algorithm [3]. There are many ways in which the implementation of a gradient descent optimisation algorithm can vary. For example, mini-batch gradient descent calculates the parameter changes every n data points, where n is a pre-defined batch size [4]. Momentum, which is calculated using the value of previous gradients, can also be added on to the parameter changes. Fundamentally however, they all calculate the gradients in the same way and use the magnitude and direction of the gradients to determine how much each parameter should be changed.\n",
        "\n",
        "Other approaches are rather unique with how parameter changes are determined and therefore almost no commonalities exist with itself and other approaches. Models that utilise simulated annealing consider the effects of random small changes to parameters. If the changes reduce the total loss, then the changes are accepted. If the changes instead generate an increase in loss, the changes can still be accepted with a probability that decreases over time [5]. In this case while the changes usually cause some loss function to be decreased, the changes are determined randomly rather than through the calculation of gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueTyo5z-E1FE",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "1.   Ransford, H.C. 2017 'Where the Question Leads', entry for the 9th FQXi Essay Contest\n",
        "2.   Cortes, C. & Vapnik, V. 1995 'Support-vector networks', *Machine Learning*, vol. 20, no. 3, pp. 273-297\n",
        "3.   Rumelhart, D.E., Hinton, G.E. & Williams, R.J. 1986 'Learning Internal Representations By Error Propagation', *Parallel distributed processing: explorations in the microstructure of cognition*, vol. 1, pp. 318-362\n",
        "4.   Li, M., Zhang, T., Chen, Y. & Smola, A.J. 2014 '\n",
        "Efficient mini-batch training for stochastic optimization', *Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining*, New York, pp. 661-670\n",
        "5.   Rere, L., Fanany, M. & Arymurthy, A. 2015 'Simulated Annealing Algorithm for Deep Learning', *Procedia Computer Science*, vol. 72, pp. 137-144.\n",
        "6.   Li, X., Deng, S., Wang, S., Lv, Z. & Wu, L. 2018 'Review of Small Data Learning Methods', *2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)*, Tokyo, pp. 106-109\n",
        "7.   Islam, M.J., Wu, Q.M.J., Ahmadi, M. & Sid-Ahmed, M.A. 2007 'Investigating the Performance of Naive- Bayes Classifiers and K- Nearest Neighbor Classifiers' *2007 International Conference on Convergence Information Technology (ICCIT 2007)*, Gyeongju, pp. 1541-1546."
      ]
    }
  ]
}