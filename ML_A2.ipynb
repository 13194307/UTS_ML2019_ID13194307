{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML A2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/13194307/UTS_ML2019_ID13194307/blob/master/ML_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7ha_Z_L9Ktn",
        "colab_type": "text"
      },
      "source": [
        "# Link to repository:\n",
        "https://github.com/13194307/UTS_ML2019_ID13194307"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwfbQcQpSa8S",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Each year, approximately 6.5 million animals in the U.S. are abandoned by their owners. In some of these cases, these pets are left on the streets to fend for themselves. However in other cases, these pets are dropped off at animal shelters where volunteer workers can take care of them. While the majority of pets at animal shelters are adopted, transferred or returned to their owners, a large proportion of shelter pets (approximately 23%) are not so fortunate and are either euthanized or experience a natural death.\n",
        "<br>\n",
        "<br>\n",
        "In an attempt to reduce the number of shelter animals who experience a negative outcome, we have decided to build a model which can predict what outcome a shelter animal is likely to experience. This information could then be used to guide actions towards increasing the likelihood of shelter animals identified by the model as 'at-risk' experiencing a positive outcome. The model will be trained off a dataset from the Austin Animal Center which contains 26727 data points on pets that were in an animal shelter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "junVkSWT9Mnj",
        "colab_type": "text"
      },
      "source": [
        "# Exploration\n",
        "The problem of predicting the outcome of shelter animals is not trivial and has many challenges associated with it. Overcoming these challenges is crucial in order to ensure that our models perform well on the dataset. An initial exploration of the dataset was conducted, in which the type, distribution and frequency of specific values for each attribute was visualised. This exploration revealed a few challenges that needed to be solved.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "The first challenge was normalising the breed and color column in such a way that it still captures the variation of pets while not producing hundreds of extra columns when one-hot encoded. One-hot encoding is necessary for this column as the data needs to be represented in a numerical manner for it to be processed by models such as neural networks and simply representing each possible attribute value with a number would create an artificial, non-existent order to the attribute. The number of columns created by one-hot encoding is equal to the number of unique values for each attribute. Since “Breed” has 1380 unique values and “Color” has 366 unique attributes, one-hot encoding these two attributes would about 1746 new attributes which would not only slow down the efficiency of the models but also decrease the performance of the models due to the ‘curse of dimensionality’, where having more features (or dimensions) requires exponentially more data to train an accurate model.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Another challenge with the dataset is converting many attributes, which were unnecessarily created as nominal attributes, into a more useful form. An example of this is the “Age” attribute, which represents the age of the pet as a string (“1 week”, “2 months”, etc). There are two problems with this:\n",
        "Like with the “Breed” and “Color” attributes, one-hot encoding the “Age” attribute would create a large number of extra attributes.\n",
        "A nominal label does not capture the ordered nature of the data (e.g. 1 week < 2 months).\n",
        "These attributes might need to have data extracted from the strings to create a new attribute, such as a boolean or numeric attribute, in order to use the information from these attributes.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "An important decision to make when planning out a solution for this business problem is what models to use. These models need to be designed for classification problems. More specifically, they need to be able to handle multi-class classification. Fortunately this isn’t a problem for most models, so the main factor for choosing models will be performance. Five models were chosen:\n",
        "* K-Nearest Neighbours (KNN): Although it is a relatively simple model, it was chosen to serve as a baseline for comparisons.\n",
        "* Support Vector Machine (SVM): A powerful model which attempts to fit a hyperplane to a dataset. Depending on the kernel chosen, SVMs can perform extremely well on a lot of problems. However they sometimes can be slow to train.\n",
        "* Random Forest: Random Forest models are notorious for their high level of performance on many datasets so it seems likely to be a potential contender for the best model on this dataset.\n",
        "* Gradient-Boosting Classifier: Chosen as it too is a very powerful model that is used extensively in Kaggle competitions.\n",
        "* Neural Network: With features such as dropout layers, neural networks are extremely powerful. However, their performance depends greatly on the size of the dataset and they can oftentimes be rather slow to train. While the issue of sample size is hard to fix, training time can be decreased with the use of a Graphical Processing Unit (GPU) or a Tensor Processing Unit (TPU). Both of these pieces of hardware can be utilised through Google’s Colab platform. This is also likely to be one of the better performing models.\n",
        "\n",
        "Each of these models will be trained on a training dataset before being evaluated on a test dataset. The results from each model will be compared in order to determine the best performing models.\n",
        "<br>\n",
        "<br>\n",
        "Finally, an evaluation metric will need to be selected as there needs to be a way of ranking the performance of models. While accuracy is one of the more well known metrics and is easier to understand for people unfamiliar with machine learning, it tends to be more easily influenced by data biases such as an imbalanced dataset. With animals that were either euthanised or died while being held at the shelter making up only 6.55% of the samples, it would be unwise to use accuracy as a metric as it would not effectively capture the performance on minority samples. F1-score, which measures performance based on precision and recall, is more suitable for imbalanced datasets. However in the end, log-loss was chosen as the evaluation metric for a few reasons. Firstly it can also handle imbalanced datasets. Secondly, log-loss evaluates models based on how far off the probability predictions were which seems more suitable for a problem where the goal is to predict the likelihood of a pet experiencing a specific outcome. Finally, the Kaggle competition that was run for this dataset used log-loss, which means that the performance of the five models mentioned above can be compared to scores on Kaggle.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps3lFCyn_Qa5",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Below are the results for each model. These results were achieved by running each model 5 times and getting the average of the results:\n",
        "\n",
        "<br>\n",
        "<table>\n",
        "  <tr>\n",
        "    <th><span style=\"font-weight:bold\">Models</span></th>\n",
        "    <th>Log-Loss</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Random Forest</td>\n",
        "    <td>0.917</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>SVM</td>\n",
        "    <td>0.916</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>KNN</td>\n",
        "    <td>0.983</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Neural Networks</td>\n",
        "    <td>0.910</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Gradient Boosting Classifier</td>\n",
        "    <td>0.863</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "<br>\n",
        "KNN performed the worst out of all the models on the dataset. This was expected as KNN is a very basic algorithm which classifies points based on the labels of its closest neighbours. Every other model performed significantly better than KNN. Random Forest, SVM and Neural Network all achieved a similar level of performance. However the Neural Network was the better performing model out of these three models. The Neural Network was expected to perform above SVM and KNN due to it’s multi-layer architecture and additional features such as dropout which both allow the Neural Network to excel at extracting features and patterns from the data. It is surprising to see the Random Forest model fail to beat the SVM. Although it only performed marginally worse, it was expected that the Random Forest model would at least outperform the SVM. Also of note is the fact that the Gradient Boosting Classifier performed well above all the other models. From a glance, this may seem strange since both Random Forest models and Gradient Boosting Classifiers are tree-based classifiers. A possible explanation as to why the Gradient Boosting Classifier performed so well is that during the training (or ‘tree-growing’) process, a lot of emphasis is placed on learning how to classify data points which the model previously struggled to classify. Since the dataset is imbalanced, this might have given the model an edge when it came to classifying these points.\n",
        "<br>\n",
        "<br>\n",
        "Compared to the results achieved in the Kaggle competition, the Gradient Boosting Classifier did fairly well. Our Gradient Boosting Classifier managed to beat around 50% of the 1600 teams who took part in the competition. It is hard to accurately determine the highest score since some of the scores on the Kaggle leaderboard were achieved through exploits. However, it appears that the best models achieved a log-loss of around 0.66 and the best published notebook for the competition achieved a log-loss of 0.71 using XGBOOST, a type of Gradient Boosting Classifier, as well as a more thorough feature selection and normalisation process. In many cases, these high scores are due to feature selection rather than what model was used. Either way, there is plenty of room for improvement for our models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEPDfE8hAzE5",
        "colab_type": "text"
      },
      "source": [
        "# Ethical\n",
        "\n",
        "An important but often neglected aspect of any data mining/data science project is considering the potential misuses of the solution created. With machine learning models as well as creations derived from the application of machine learning techniques becoming more and more powerful, their possibility for being put to use in an unethical manner grows larger. \n",
        "<br>\n",
        "<br>\n",
        "From a cursory exploration of the problem, and even from a somewhat more in-depth exploration, it would seem as if there would be no consequence to creating a model for predicting the outcome of pets in animal shelters. In fact, according to both consequentialist ethics (e.g. utilitarian) and deontological ethics (e.g. Kantian), it might be considered morally right (although this brings into question as to what extent are pets worthy of moral consideration by humans) to implement this model as animal shelters, armed with the knowledge of which pets are more at risk of being euthanised or dying, could direct efforts towards increasing the odds of a better outcome for these pets.\n",
        "<br>\n",
        "<br>\n",
        "In reality however, the opposite effect may occur. Although animal shelters are not-for-profit, they still will take actions that reduce the operation cost of their business. In some cases, these actions may be at the expense of others. Animal shelters might decide that it is too much of a risk to spend money on caring for pets which are more likely to experience a negative outcome and either not accept these pets into the shelter or euthanise them without giving them a chance. In this case, if reducing the number of pets dying was the goal, then not implementing the model may have been the better choice since it would produce a better outcome. This decision would be in line with utilitarian thinking, where the ends justify the means, but it might conflict with Kantian ethics, which states that some actions are never morally right despite whatever outcome is produced, as many people would consider withholding the information that could be produced from the model to be morally wrong.\n",
        "<br>\n",
        "<br>\n",
        "The above situation is theoretical, and what may actually occur as a result of implementing this model is unknown. It would seem probable that the misuse of the model would only occur if funding for animal shelters decreased, which would create a need to cut costs by rejecting or euthanizing more animals. However it seems just as likely that this situation would occur anyways, even without the model. The only difference would be the choice of animals that are selected to be euthanized or rejected. From this perspective, it seems like implementing the model is the better choice as there is less of a risk for a negative outcome.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4vKWJMpURLg",
        "colab_type": "text"
      },
      "source": [
        "# References\n",
        "https://www.aspca.org/animal-homelessness/shelter-intake-and-surrender/pet-statistics"
      ]
    }
  ]
}